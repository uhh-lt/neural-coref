include "local.conf"

base {
  data_dir = ${base_dir}/data

  conll_scorer = ${base_dir}/data/reference-coreference-scorers/v8.01/scorer.pl

  # Computation limits.
  max_top_antecedents = 10
  max_training_sentences = 5
  top_span_ratio = 0.4
  max_num_extracted_spans = 3900
  max_num_speakers = 20
  max_segment_len = 256
  long_doc_strategy = split
  postprocess_merge_overlapping_spans = true

  # Learning
  bert_learning_rate = 1e-5
  task_learning_rate = 2e-4
  loss_type = marginalized  # {marginalized, hinge}
  mention_loss_coef = 0
  false_new_delta = 1.5  # For loss_type = hinge
  adam_eps = 1e-6
  adam_weight_decay = 1e-2
  warmup_ratio = 0.1
  max_grad_norm = 1  # Set 0 to disable clipping
  gradient_accumulation_steps = 1
  doc_max_segments = 20

  # Model hyperparameters.
  coref_depth = 1  # when 1: no higher order (except for cluster_merging)
  higher_order = attended_antecedent # {attended_antecedent, max_antecedent, entity_equalization, span_clustering, cluster_merging}
  coarse_to_fine = true
  fine_grained = true
  dropout_rate = 0.3
  ffnn_size = 2048
  ffnn_depth = 1
  cluster_ffnn_size = 2048   # For cluster_merging
  cluster_reduce = mean  # For cluster_merging
  easy_cluster_first = false  # For cluster_merging
  cluster_dloss = false  # cluster_merging
  num_epochs = 24
  feature_emb_size = 20
  max_span_width = 30
  span_width_embedding_size = 30
  use_metadata = false
  use_features = true
  use_segment_distance = true
  model_heads = true
  use_width_prior = true  # For mention score
  use_distance_prior = true  # For mention-ranking score
  model_type = bert
  freeze_mention_score = false

  # Incremental
  incremental_start_global_loss_ratio = 0.0
  incremental_end_global_loss_ratio = 0.0
  incremental_teacher_forcing = true
  incremental_singletons = false

  evict = true
  unconditional_eviction_limit = 1500
  singleton_eviction_limit = 400
  num_antecedent_distance_buckets = 30


  # Other.
  conll_eval_path = ${base.data_dir}/dev.german.tuebdz_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/test.german.tuebdz_gold_conll  # gold_conll file for test
  genres = ["n"]
  eval_frequency = 200
  report_frequency = 100
  log_root = ${base.data_dir}
}

droc_short = ${base}{
  max_span_width = 8
  num_epochs = 30
  incremental = false
  mention_loss_coef = 0.5
  ffnn_depth = 1

  max_segment_len = 512

  language = german
  data_dir = ${base.data_dir}/droc_short
  conll_eval_path = ${base.data_dir}/droc_short/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_short/test.german.droc_gold_conll  # gold_conll file for test

  bert_tokenizer_name = german-nlp-group/electra-base-german-uncased
  bert_pretrained_name_or_path = german-nlp-group/electra-base-german-uncased
  model_type = electra
}

droc_c2f = ${droc_short}{
  mention_loss_coef = 0.0
  max_training_sentences = 13
  doc_max_segments = 30

  task_learning_rate = 3e-4

  data_dir = ${base.data_dir}/droc_full
  conll_eval_path = ${base.data_dir}/droc_full/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_full/test.german.droc_gold_conll  # gold_conll file for test
}

droc_c2f_nosingletons = ${droc_c2f}{
  data_dir = ${base.data_dir}/droc_full_nosingletons
  conll_eval_path = ${base.data_dir}/droc_full_nosingletons/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_full_nosingletons/test.german.droc_gold_conll  # gold_conll file for test
}

##
## Incremental model with singletons in the data file
##

droc_incremental = ${droc_c2f}{
  incremental_teacher_forcing = false
  long_doc_strategy = keep
  incremental_start_global_loss_ratio = 0.0
  incremental_end_global_loss_ratio = 0.0
  mention_loss_coef = 0.0

  new_cluster_threshold = 0.0
  memory_limit = ${memory_limit}
  incremental = true
  eval_frequency = 100
  num_epochs = 40

  bert_learning_rate = 1e-5
  task_learning_rate = 7e-5
}

droc_incremental_teacherforcing = ${droc_incremental}{
  incremental_teacher_forcing = true
  incremental_singletons = false
}

droc_incremental_teacherforcing_discard = ${droc_incremental}{
  incremental_teacher_forcing = true
  incremental_singletons = true
}

droc_incremental_discard = ${droc_incremental}{
  incremental_teacher_forcing = false
  incremental_singletons = true
}

##
## Incremental models with no singeltons in data file
##

droc_short_nosingletons = ${droc_short}{
  data_dir = ${base.data_dir}/data_droc_short_nosingletons
  conll_eval_path = ${base.data_dir}/droc_short_nosingletons/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_short_nosingletons/test.german.droc_gold_conll  # gold_conll file for test
}

droc_incremental_nosingletons = ${droc_incremental}{
  incremental_teacher_forcing = false
  incremental_singletons = false

  data_dir = ${base.data_dir}/droc_full_nosingletons
  conll_eval_path = ${base.data_dir}/droc_full_nosingletons/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_full_nosingletons/test.german.droc_gold_conll  # gold_conll file for test
}

droc_incremental_nosingletons_teacherforcing = ${droc_incremental_nosingletons}{
  incremental_teacher_forcing = true
  incremental_singletons = false
}

droc_incremental_nosingletons_teacherforcing_discard = ${droc_incremental_nosingletons}{
  # Since we discard most mentions the remaining ones are singletons
  incremental_teacher_forcing = true
  incremental_singletons = true
}

droc_incremental_nosingletons_discard = ${droc_incremental_nosingletons}{
  incremental_teacher_forcing = false
  incremental_singletons = true
}


##
## Snippet Experiments
##

# 512-splits
droc_incremental_split_512 = ${droc_incremental_teacherforcing_discard}{
  data_dir = ${base.data_dir}/droc_split_512
  conll_eval_path = ${base.data_dir}/droc_split_512/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_split_512/test.german.droc_gold_conll  # gold_conll file for test
}

droc_c2f_split_512 = ${droc_c2f}{
  data_dir = ${base.data_dir}/droc_split_512
  conll_eval_path = ${base.data_dir}/droc_split_512/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_split_512/test.german.droc_gold_conll  # gold_conll file for test
}

# 1024-splits
droc_incremental_split_1024 = ${droc_incremental_teacherforcing_discard}{
  data_dir = ${base.data_dir}/droc_split_1024
  conll_eval_path = ${base.data_dir}/droc_split_1024/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_split_1024/test.german.droc_gold_conll  # gold_conll file for test
}

droc_c2f_split_1024 = ${droc_c2f}{
  data_dir = ${base.data_dir}/droc_split_1024
  conll_eval_path = ${base.data_dir}/droc_split_1024/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_split_1024/test.german.droc_gold_conll  # gold_conll file for test
}


# 2048-splits
droc_incremental_split_2048 = ${droc_incremental_teacherforcing_discard}{
  data_dir = ${base.data_dir}/droc_split_2048
  conll_eval_path = ${base.data_dir}/droc_split_2048/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_split_2048/test.german.droc_gold_conll  # gold_conll file for test
}

droc_c2f_split_2048 = ${droc_c2f}{
  data_dir = ${base.data_dir}/droc_split_2048
  conll_eval_path = ${base.data_dir}/droc_split_2048/dev.german.droc_gold_conll  # gold_conll file for dev
  conll_test_path = ${base.data_dir}/droc_split_2048/test.german.droc_gold_conll  # gold_conll file for test
}

# Experiments for block building
droc_c2f_no_features = ${droc_c2f}{
  use_features = false
  use_segment_distance = true
}

droc_c2f_no_features_no_segment_distance = ${droc_c2f}{
  use_features = false
  use_segment_distance = false
}

droc_c2f_no_segment_distance = ${droc_c2f}{
  use_features = true
  use_segment_distance = false
}

droc_incremental_no_features = ${droc_incremental}{
  use_features = false
  use_segment_distance = true
}

droc_incremental_no_features_discard = ${droc_incremental_discard}{
  use_features = false
  use_segment_distance = true
}

droc_incremental_no_features = ${droc_incremental_discard} {
  use_features = false
  use_segment_distance = true
}

droc_incremental_no_segment_distance = ${droc_incremental_discard} {
  use_features = true
  use_segment_distance = false
}

droc_incremental_no_features_no_segment_distance = ${droc_incremental_discard} {
  use_features = false
  use_segment_distance = false
}

##
## News (c2f)
##

news = ${base}{
  max_top_antecedents = 64
  max_num_extracted_spans = 4096
  max_segment_len = 512
  doc_max_segments = 12
  num_antecedent_distance_buckets = 10
  model_type = electra
  incremental = false
  postprocess_merge_overlapping_spans = false
  language = german
}

# SemEval 2010

se10 = ${news}{
  conll_eval_path = ${base.data_dir}/dev.german.v4_gold_conll
  conll_test_path = ${base.data_dir}/test.german.v4_gold_conll
  num_epochs = 48
  long_doc_strategy = truncate
}

se10_electra_uncased = ${se10}{
  data_dir = ${base.data_dir}/se10_electra_uncased
  bert_tokenizer_name = german-nlp-group/electra-base-german-uncased
  bert_pretrained_name_or_path = german-nlp-group/electra-base-german-uncased
}

se10_gelectra_large = ${se10}{
  data_dir = ${se10.data_dir}/gelectra-large
  max_training_sentences = 2
  bert_tokenizer_name = deepset/gelectra-large
  bert_pretrained_name_or_path = deepset/gelectra-large
}

# TuBa-D/Z 10.0

tuba10 = ${news}{
  conll_eval_path = ${base.data_dir}/dev.german.tuebdz_gold_conll
  conll_test_path = ${base.data_dir}/test.german.tuebdz_gold_conll
  max_training_sentences = 3
  num_epochs = 24
}

tuba10_electra_uncased = ${tuba10}{
  data_dir = ${tuba10.data_dir}/tuba10_electra_uncased
  bert_tokenizer_name = german-nlp-group/electra-base-german-uncased
  bert_pretrained_name_or_path = german-nlp-group/electra-base-german-uncased
  long_doc_strategy = even-chunks
}

tuba10_gelectra_large = ${tuba10}{
  data_dir = ${tuba10.data_dir}/tuba10_gelectra-large
  long_doc_strategy = split
  bert_tokenizer_name = deepset/gelectra-large
  bert_pretrained_name_or_path = deepset/gelectra-large
  long_doc_strategy = split
}
